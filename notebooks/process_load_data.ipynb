{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Process the Load Data for the Nuclear Heat Wave Grid Stress Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and image output directory:\n",
    "data_dir =  '/Users/burl878/Documents/Code/code_repos/nuclear_heat_wave_loads/data/'\n",
    "plot_dir =  '/Users/burl878/Documents/Code/code_repos/nuclear_heat_wave_loads/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb4d0d-a7cd-4dbf-aa21-c1b162873993",
   "metadata": {},
   "source": [
    "## Suppress Future Warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f4aa11-ca79-407d-a18d-4c29e63fed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78893b17-7c20-4ea5-8292-90dea6799307",
   "metadata": {},
   "source": [
    "## Create a Function to Process the 2030 GridView Data Used in Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f99e5c4-6575-4d2e-843b-21064c017f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gridview_data(data_dir: str):\n",
    "    \n",
    "    # Read in the raw data .csv file:\n",
    "    gv_df = pd.read_csv((data_dir + 'WECC_2030_LOAD.csv'))\n",
    "    \n",
    "    # Subset to just the annual total demand by BA:\n",
    "    gv_df = gv_df[-3:-2]\n",
    "       \n",
    "    # Strip the unecessary bits from the column names:\n",
    "    gv_df.columns = gv_df.columns.str.replace(\"_CEC\", \"\")\n",
    "    gv_df.columns = gv_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "    gv_df.columns = gv_df.columns.str.replace(\"Load_\", \"\")\n",
    "       \n",
    "    # Delete the index column:\n",
    "    del gv_df[\"Index\"], gv_df[\"Unnamed: 44\"]\n",
    "    \n",
    "    # Convert the values to floats:\n",
    "    gv_df = gv_df.astype(float)\n",
    "    \n",
    "    # Compute the total loads for CISO, IPCO, NEVP, and PACE:\n",
    "    gv_df['CISO'] = (gv_df['CIPB'] + gv_df['CIPV'] + gv_df['CISC'] + gv_df['CISD'] + gv_df['VEA']).round(2)\n",
    "    gv_df['IPCO'] = (gv_df['IPFE'] + gv_df['IPMV'] + gv_df['IPTV']).round(2)\n",
    "    gv_df['PACE'] = (gv_df['PAID'] + gv_df['PAUT'] + gv_df['PAWY']).round(2)\n",
    "    gv_df['NEVP_Sum'] = (gv_df['NEVP'] + gv_df['SPPC']).round(2)\n",
    "           \n",
    "    # Rename a few columns for consistency:\n",
    "    gv_df.rename(columns={'CIPB': 'CISO_CIPB', 'CIPV': 'CISO_CIPV', 'CISC': 'CISO_CISC', 'CISD': 'CISO_CISD', 'VEA': 'CISO_VEA',\n",
    "                          'IPFE': 'IPCO_IPFE', 'IPMV': 'IPCO_IPMV', 'IPTV': 'IPCO_IPTV',\n",
    "                          'NEVP': 'NEVP_NEVP', 'SPPC': 'NEVP_SPPC',\n",
    "                          'PAID': 'PACE_PAID', 'PAUT': 'PACE_PAUT', 'PAWY': 'PACE_PAWY'}, inplace=True) \n",
    "    gv_df.rename(columns={'NEVP_Sum': 'NEVP'}, inplace=True) \n",
    "    \n",
    "    # Squeeze the dataframe:\n",
    "    gv_df = gv_df.squeeze().to_frame()\n",
    "        \n",
    "    # Rename the columns:\n",
    "    gv_df.reset_index(inplace=True)\n",
    "    gv_df = gv_df.rename(columns = {'index':'BA'})\n",
    "    gv_df.rename(columns={gv_df.columns[1]: \"Total_Load_MWh\" }, inplace = True)\n",
    "       \n",
    "    # Sort the dataframe alphabetically by BA name:\n",
    "    gv_df = gv_df.sort_values('BA')\n",
    "       \n",
    "    # Return the output dataframe:\n",
    "    return gv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7c785c4-9a3b-497c-8cf4-b2f060c2f7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BA</th>\n",
       "      <th>GV_Total_Load_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AESO</td>\n",
       "      <td>96334990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVA</td>\n",
       "      <td>13700840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZPS</td>\n",
       "      <td>43196860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANC</td>\n",
       "      <td>18552430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCHA</td>\n",
       "      <td>65680680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPAT</td>\n",
       "      <td>69348320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CFE</td>\n",
       "      <td>22031280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHPD</td>\n",
       "      <td>1971675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CISO</td>\n",
       "      <td>247877970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CISO_CIPB</td>\n",
       "      <td>48892610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CISO_CIPV</td>\n",
       "      <td>63754560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CISO_CISC</td>\n",
       "      <td>110057200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CISO_CISD</td>\n",
       "      <td>24422510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CISO_VEA</td>\n",
       "      <td>751090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DOPD</td>\n",
       "      <td>2186102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EPE</td>\n",
       "      <td>10962210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GCPD</td>\n",
       "      <td>10598970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IID</td>\n",
       "      <td>4257471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>IPCO</td>\n",
       "      <td>19557205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IPCO_IPFE</td>\n",
       "      <td>2606724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IPCO_IPMV</td>\n",
       "      <td>5518111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IPCO_IPTV</td>\n",
       "      <td>11432370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LDWP</td>\n",
       "      <td>34156140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NEVP</td>\n",
       "      <td>34694160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEVP_NEVP</td>\n",
       "      <td>23654660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NEVP_SPPC</td>\n",
       "      <td>11039500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NWMT</td>\n",
       "      <td>13233980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PACE</td>\n",
       "      <td>53126920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PACE_PAID</td>\n",
       "      <td>6390177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PACE_PAUT</td>\n",
       "      <td>36744980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PACE_PAWY</td>\n",
       "      <td>9991763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PACW</td>\n",
       "      <td>22468990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PGE</td>\n",
       "      <td>22572620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PNM</td>\n",
       "      <td>15050870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PSCO</td>\n",
       "      <td>53300760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PSEI</td>\n",
       "      <td>25807330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SCL</td>\n",
       "      <td>8976500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SRP</td>\n",
       "      <td>40099720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TEPC</td>\n",
       "      <td>18272900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TH_Malin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TH_Mead</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TH_PV</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TIDC</td>\n",
       "      <td>2861704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TPWR</td>\n",
       "      <td>4889470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WACM</td>\n",
       "      <td>28129700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WALC</td>\n",
       "      <td>9656130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>WAUW</td>\n",
       "      <td>841191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BA  GV_Total_Load_MWh\n",
       "0        AESO         96334990.0\n",
       "1         AVA         13700840.0\n",
       "2        AZPS         43196860.0\n",
       "3        BANC         18552430.0\n",
       "4        BCHA         65680680.0\n",
       "5        BPAT         69348320.0\n",
       "6         CFE         22031280.0\n",
       "7        CHPD          1971675.0\n",
       "43       CISO        247877970.0\n",
       "8   CISO_CIPB         48892610.0\n",
       "9   CISO_CIPV         63754560.0\n",
       "10  CISO_CISC        110057200.0\n",
       "11  CISO_CISD         24422510.0\n",
       "39   CISO_VEA           751090.0\n",
       "12       DOPD          2186102.0\n",
       "13        EPE         10962210.0\n",
       "14       GCPD         10598970.0\n",
       "15        IID          4257471.0\n",
       "44       IPCO         19557205.0\n",
       "16  IPCO_IPFE          2606724.0\n",
       "17  IPCO_IPMV          5518111.0\n",
       "18  IPCO_IPTV         11432370.0\n",
       "19       LDWP         34156140.0\n",
       "46       NEVP         34694160.0\n",
       "20  NEVP_NEVP         23654660.0\n",
       "31  NEVP_SPPC         11039500.0\n",
       "21       NWMT         13233980.0\n",
       "45       PACE         53126920.0\n",
       "23  PACE_PAID          6390177.0\n",
       "24  PACE_PAUT         36744980.0\n",
       "25  PACE_PAWY          9991763.0\n",
       "22       PACW         22468990.0\n",
       "26        PGE         22572620.0\n",
       "27        PNM         15050870.0\n",
       "28       PSCO         53300760.0\n",
       "29       PSEI         25807330.0\n",
       "30        SCL          8976500.0\n",
       "32        SRP         40099720.0\n",
       "33       TEPC         18272900.0\n",
       "34   TH_Malin                0.0\n",
       "35    TH_Mead                0.0\n",
       "36      TH_PV                0.0\n",
       "37       TIDC          2861704.0\n",
       "38       TPWR          4889470.0\n",
       "40       WACM         28129700.0\n",
       "41       WALC          9656130.0\n",
       "42       WAUW           841191.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the processed GridView file and rename a column for consistency:\n",
    "gv_df = process_gridview_data(data_dir = data_dir)\n",
    "gv_df.rename(columns={'Total_Load_MWh': 'GV_Total_Load_MWh'}, inplace=True) \n",
    "\n",
    "gv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9778e2e-41a0-4a77-b985-40a3cfaba372",
   "metadata": {},
   "source": [
    "## Create a Function to Aggregate the Raw TELL MLP Output into a Single Dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e4dd356-95b4-43e8-987a-1012754a25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_mlp_output_files(data_dir: str, year_to_process: str):\n",
    "    \n",
    "    # Create a list of all of the MLP output files in the \"mlp_input_dir\" and aggregate the files in that list:\n",
    "    list_of_files = sorted(glob.glob(os.path.join(data_dir, 'TELL_Data', year_to_process, '*_mlp_output.csv')))\n",
    "\n",
    "    # Loop over the list of MLP output files:\n",
    "    for file in range(len(list_of_files)):\n",
    "\n",
    "        # Read in the .csv file and replace missing values with nan:\n",
    "        mlp_data = pd.read_csv(list_of_files[file]).replace(-9999, np.nan)\n",
    "\n",
    "        # Rename the \"Load\" variable:\n",
    "        mlp_data.rename(columns={'Load': 'Hourly_Load_MWh'}, inplace=True)\n",
    "\n",
    "        # Replacing missing or negative loads with NaN:\n",
    "        mlp_data.loc[~(mlp_data['Hourly_Load_MWh'] > 0), 'Hourly_Load_MWh'] = np.nan\n",
    "\n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if file == 0:\n",
    "            tell_df = mlp_data\n",
    "        else:\n",
    "            tell_df = pd.concat([tell_df, mlp_data])\n",
    "    \n",
    "    # Return the output dataframe:\n",
    "    return tell_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c489f3c-66e8-4359-9e02-19057e5d87d3",
   "metadata": {},
   "source": [
    "## Create a Function to Scale the TELL Output Based on the GridView 2030 Values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6412c8be-a4c5-4f58-8026-8ffd637ec7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_tell_loads(data_dir: str, year_to_process: str):\n",
    "    \n",
    "    # Aggregate the TELL MLP files:\n",
    "    tell_df = aggregate_mlp_output_files(data_dir = data_dir,\n",
    "                                         year_to_process = year_to_process)\n",
    "    \n",
    "    # Read in the processed GridView file and rename a column for consistency:\n",
    "    gv_df = process_gridview_data(data_dir = data_dir)\n",
    "    gv_df.rename(columns={'Total_Load_MWh': 'GV_Total_Load_MWh'}, inplace=True) \n",
    "    \n",
    "    # Merge the tell_df and gv_df dataframes based on common BA names:\n",
    "    merged_df = tell_df.merge(gv_df, on=['BA'])\n",
    "    \n",
    "    # Sum the hourly TELL loads by BA into annual total loads:\n",
    "    merged_df['TELL_Total_Load_MWh'] = merged_df.groupby('BA')['Hourly_Load_MWh'].transform('sum')\n",
    "    \n",
    "    # Compute the scaling factors that force the annual total loads to agree:\n",
    "    merged_df['Scaling_Factor'] = merged_df['GV_Total_Load_MWh'] / merged_df['TELL_Total_Load_MWh']\n",
    "    \n",
    "    # Compute the scaled hourly loads:\n",
    "    merged_df['Hourly_Load_MWh_Scaled'] = merged_df['Hourly_Load_MWh'] * merged_df['Scaling_Factor']\n",
    "    \n",
    "    # Compute the hours since the start of the year:\n",
    "    merged_df['Hour'] = ((pd.to_datetime(merged_df['Time_UTC']) - datetime.datetime(int(year_to_process), 1, 1, 0, 0, 0)) / np.timedelta64(1, 'h') + 1).astype(int)\n",
    "    \n",
    "    # Only keep the columns that are needed:\n",
    "    scaled_tell_df = merged_df[['Hour', 'BA', 'Hourly_Load_MWh_Scaled']].copy()\n",
    "    \n",
    "    # Drop the rows with missing values (i.e., there is not a corresponding GridView load):\n",
    "    scaled_tell_df = scaled_tell_df.dropna(how = 'any')\n",
    "    \n",
    "    # Rename the load variable and round it to 5 decimals:\n",
    "    scaled_tell_df.rename(columns={'Hourly_Load_MWh_Scaled': 'Load_MWh'}, inplace=True)\n",
    "    scaled_tell_df['Load_MWh'] = scaled_tell_df['Load_MWh'].round(5)\n",
    "    \n",
    "    # Return the output dataframe:\n",
    "    return scaled_tell_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db940a-bc5b-42ca-b1e6-2a97e5d7c009",
   "metadata": {},
   "source": [
    "## Create a Function to Format the Output for Ingest to GridView:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25c2d2d2-dadf-45cf-b0e1-40b8856595f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scaled_tell_loads(data_dir: str, year_to_process: str):\n",
    "    \n",
    "    # Process the GridView file:\n",
    "    gv_df = process_gridview_data(data_dir = data_dir)\n",
    "    \n",
    "    # Compute the load fractions for the subregions:\n",
    "    CIPB_LF = (gv_df.loc[(gv_df['BA'] == 'CISO_CIPB')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'CISO')]['Total_Load_MWh'].values[0])\n",
    "    CIPV_LF = (gv_df.loc[(gv_df['BA'] == 'CISO_CIPV')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'CISO')]['Total_Load_MWh'].values[0])\n",
    "    CISC_LF = (gv_df.loc[(gv_df['BA'] == 'CISO_CISC')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'CISO')]['Total_Load_MWh'].values[0])\n",
    "    CISD_LF = (gv_df.loc[(gv_df['BA'] == 'CISO_CISD')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'CISO')]['Total_Load_MWh'].values[0])\n",
    "    VEA_LF  = (gv_df.loc[(gv_df['BA'] == 'CISO_VEA' )]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'CISO')]['Total_Load_MWh'].values[0])\n",
    "    IPFE_LF = (gv_df.loc[(gv_df['BA'] == 'IPCO_IPFE')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'IPCO')]['Total_Load_MWh'].values[0])\n",
    "    IPMV_LF = (gv_df.loc[(gv_df['BA'] == 'IPCO_IPMV')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'IPCO')]['Total_Load_MWh'].values[0])\n",
    "    IPTV_LF = (gv_df.loc[(gv_df['BA'] == 'IPCO_IPTV')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'IPCO')]['Total_Load_MWh'].values[0])\n",
    "    NEVP_LF = (gv_df.loc[(gv_df['BA'] == 'NEVP_NEVP')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'NEVP')]['Total_Load_MWh'].values[0])\n",
    "    SPPC_LF = (gv_df.loc[(gv_df['BA'] == 'NEVP_SPPC')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'NEVP')]['Total_Load_MWh'].values[0])\n",
    "    PAID_LF = (gv_df.loc[(gv_df['BA'] == 'PACE_PAID')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'PACE')]['Total_Load_MWh'].values[0])\n",
    "    PAUT_LF = (gv_df.loc[(gv_df['BA'] == 'PACE_PAUT')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'PACE')]['Total_Load_MWh'].values[0])\n",
    "    PAWY_LF = (gv_df.loc[(gv_df['BA'] == 'PACE_PAWY')]['Total_Load_MWh'].values[0]) / (gv_df.loc[(gv_df['BA'] == 'PACE')]['Total_Load_MWh'].values[0])\n",
    "    \n",
    "    # Aggregate the TELL MLP files:\n",
    "    scaled_tell_df = scale_tell_loads(data_dir = data_dir, \n",
    "                                      year_to_process = year_to_process)\n",
    "   \n",
    "    # Reshape the dataframe and drop the indexes:\n",
    "    load_df = scaled_tell_df.pivot(index = 'Hour', columns = 'BA', values = 'Load_MWh')\n",
    "    load_df = load_df.reset_index(drop=False)\n",
    "    \n",
    "    # Add back in the text to the column headers:\n",
    "    load_df = load_df.add_suffix('_2030.dat')\n",
    "    load_df = load_df.add_prefix('Load_')\n",
    "    \n",
    "    # Rename the time variable:\n",
    "    load_df.rename(columns={'Load_Hour_2030.dat': 'Index'}, inplace=True)\n",
    "    \n",
    "    # Compute the loads for the subregions:\n",
    "    load_df['Load_CIPB_2030_CEC.dat'] = load_df['Load_CISO_2030.dat'] * CIPB_LF\n",
    "    load_df['Load_CIPV_2030_CEC.dat'] = load_df['Load_CISO_2030.dat'] * CIPV_LF\n",
    "    load_df['Load_CISC_2030_CEC.dat'] = load_df['Load_CISO_2030.dat'] * CISC_LF\n",
    "    load_df['Load_CISD_2030_CEC.dat'] = load_df['Load_CISO_2030.dat'] * CISD_LF\n",
    "    load_df['Load_VEA_2030.dat'] = load_df['Load_CISO_2030.dat'] * VEA_LF\n",
    "    load_df['Load_IPFE_2030.dat'] = load_df['Load_IPCO_2030.dat'] * IPFE_LF\n",
    "    load_df['Load_IPMV_2030.dat'] = load_df['Load_IPCO_2030.dat'] * IPMV_LF\n",
    "    load_df['Load_IPTV_2030.dat'] = load_df['Load_IPCO_2030.dat'] * IPTV_LF\n",
    "    load_df['Load_NEVP_Temp_2030.dat'] = load_df['Load_NEVP_2030.dat'] * NEVP_LF\n",
    "    load_df['Load_SPPC_2030.dat'] = load_df['Load_NEVP_2030.dat'] * SPPC_LF\n",
    "    load_df['Load_PAID_2030.dat'] = load_df['Load_PACE_2030.dat'] * PAID_LF\n",
    "    load_df['Load_PAUT_2030.dat'] = load_df['Load_PACE_2030.dat'] * PAUT_LF\n",
    "    load_df['Load_PAWY_2030.dat'] = load_df['Load_PACE_2030.dat'] * PAWY_LF\n",
    "    \n",
    "    # Drop the un-needed columns for BAs with subregions:\n",
    "    del load_df['Load_NEVP_2030.dat'], load_df['Load_CISO_2030.dat'], load_df['Load_IPCO_2030.dat'], load_df['Load_PACE_2030.dat']\n",
    "\n",
    "    # Clean up the NEVP naming:\n",
    "    load_df.rename(columns={'Load_NEVP_Temp_2030.dat': 'Load_NEVP_2030.dat'}, inplace=True)\n",
    "    \n",
    "    # Read in the raw data GridView .csv file:\n",
    "    raw_gv_df = pd.read_csv((data_dir + 'WECC_2030_LOAD.csv'))\n",
    "    \n",
    "    # Delete the index column:\n",
    "    del raw_gv_df[\"Index\"] \n",
    "    \n",
    "    # Subset to just the rows we need:\n",
    "    raw_gv_df = raw_gv_df[1:8761]\n",
    "    \n",
    "    # Convert the values to floats:\n",
    "    raw_gv_df = raw_gv_df.astype('float64')\n",
    "    \n",
    "    # Shift the index by -1:\n",
    "    raw_gv_df = raw_gv_df.reset_index()\n",
    "    \n",
    "    # Merge in the GridView columns that aren't modeled by TELL:\n",
    "    load_df = pd.concat([load_df,raw_gv_df['Load_AESO_2030.dat']], axis=1)\n",
    "    load_df = pd.concat([load_df,raw_gv_df['Load_BCHA_2030.dat']], axis=1)\n",
    "    load_df = pd.concat([load_df,raw_gv_df['Load_CFE_2030.dat']], axis=1)\n",
    "    load_df = pd.concat([load_df,raw_gv_df['Load_TH_Malin_2030.dat']], axis=1)\n",
    "    load_df = pd.concat([load_df,raw_gv_df['Load_TH_Mead_2030.dat']], axis=1)\n",
    "    load_df = pd.concat([load_df,raw_gv_df['Load_TH_PV_2030.dat']], axis=1)\n",
    "    \n",
    "    # Create a target dataframe with the spare hours:\n",
    "    target_df = pd.DataFrame({\"Index\": np.arange(1,8791,1)})\n",
    "    \n",
    "    # Merge load dataframe with the target dataframe:\n",
    "    merged_df = target_df.merge(load_df, on=['Index'], how='left')\n",
    "    \n",
    "    # Compute the summary statistics:\n",
    "    stats_df = merged_df.apply(['mean','sum','max','min'])\n",
    "    \n",
    "    # Fix the summary statistic labels:\n",
    "    stats_df.iloc[0, 0] = 'AVG'\n",
    "    stats_df.iloc[1, 0] = 'SUM'\n",
    "    stats_df.iloc[2, 0] = 'MAX'\n",
    "    stats_df.iloc[3, 0] = 'MIN'\n",
    "      \n",
    "    # Sort the data by column name and make the Index column appear first:\n",
    "    merged_df.rename(columns={'Index': 'AA'}, inplace=True)\n",
    "    merged_df = merged_df.sort_index(axis = 1)\n",
    "    merged_df.rename(columns={'AA': 'Index'}, inplace=True)\n",
    "    \n",
    "    # Add in a blank row and fill it with the year placeholder:\n",
    "    merged_df.loc[-0.5] = 0\n",
    "    merged_df = merged_df.sort_index().reset_index(drop=True)\n",
    "    merged_df.iloc[0, :] = '2030'\n",
    "    merged_df.at[0, 'Index'] = 'Year'\n",
    "        \n",
    "    # Merge the hourly load data and statistics dataframes together:\n",
    "    output_df = pd.concat([merged_df, stats_df], axis=0)\n",
    "    \n",
    "    # Replace NaNs with blank values:\n",
    "    output_df.replace(np.nan, \"\", regex=True)\n",
    "    \n",
    "    # Set the output filename:\n",
    "    if year_to_process == '2015':\n",
    "       output_filename = 'TELL_Loads_2030_Based_on_2015_Weather.csv'\n",
    "    if year_to_process == '2018':\n",
    "       output_filename = 'TELL_Loads_2030_Based_on_2018_Weather.csv'\n",
    "    if year_to_process == '2055':\n",
    "       output_filename = 'TELL_Loads_2030_Based_on_2015_Weather_With_Climate_Change.csv'\n",
    "    if year_to_process == '2058':\n",
    "       output_filename = 'TELL_Loads_2030_Based_on_2018_Weather_With_Climate_Change.csv'\n",
    "    \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv((os.path.join(data_dir, output_filename)), sep=',', index=False)\n",
    "    \n",
    "    # Return the output dataframe:\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98b6ea-1ed0-4135-a547-4bbe941202f3",
   "metadata": {},
   "source": [
    "## Call the Necessary Functions to Process the Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcfdc9dd-cac3-4091-a81b-2232bf4b083b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Load_AESO_2030.dat</th>\n",
       "      <th>Load_AVA_2030.dat</th>\n",
       "      <th>Load_AZPS_2030.dat</th>\n",
       "      <th>Load_BANC_2030.dat</th>\n",
       "      <th>Load_BCHA_2030.dat</th>\n",
       "      <th>Load_BPAT_2030.dat</th>\n",
       "      <th>Load_CFE_2030.dat</th>\n",
       "      <th>Load_CHPD_2030.dat</th>\n",
       "      <th>Load_CIPB_2030_CEC.dat</th>\n",
       "      <th>...</th>\n",
       "      <th>Load_TEPC_2030.dat</th>\n",
       "      <th>Load_TH_Malin_2030.dat</th>\n",
       "      <th>Load_TH_Mead_2030.dat</th>\n",
       "      <th>Load_TH_PV_2030.dat</th>\n",
       "      <th>Load_TIDC_2030.dat</th>\n",
       "      <th>Load_TPWR_2030.dat</th>\n",
       "      <th>Load_VEA_2030.dat</th>\n",
       "      <th>Load_WACM_2030.dat</th>\n",
       "      <th>Load_WALC_2030.dat</th>\n",
       "      <th>Load_WAUW_2030.dat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>1855.42866</td>\n",
       "      <td>3499.07666</td>\n",
       "      <td>1852.90065</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>8549.39306</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>334.84827</td>\n",
       "      <td>4769.321035</td>\n",
       "      <td>...</td>\n",
       "      <td>2122.3013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.79283</td>\n",
       "      <td>695.48727</td>\n",
       "      <td>73.266478</td>\n",
       "      <td>3608.86928</td>\n",
       "      <td>873.76981</td>\n",
       "      <td>136.69212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10826.0</td>\n",
       "      <td>1920.4559</td>\n",
       "      <td>3790.31341</td>\n",
       "      <td>1978.66392</td>\n",
       "      <td>7440.0</td>\n",
       "      <td>9054.1644</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>341.05731</td>\n",
       "      <td>5013.626145</td>\n",
       "      <td>...</td>\n",
       "      <td>2114.66879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.11039</td>\n",
       "      <td>732.00902</td>\n",
       "      <td>77.019502</td>\n",
       "      <td>3649.12892</td>\n",
       "      <td>897.7324</td>\n",
       "      <td>136.43041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10744.0</td>\n",
       "      <td>1977.53983</td>\n",
       "      <td>3921.62148</td>\n",
       "      <td>2005.747</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>9346.09489</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>335.90945</td>\n",
       "      <td>5170.056636</td>\n",
       "      <td>...</td>\n",
       "      <td>2069.61747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257.7363</td>\n",
       "      <td>748.87075</td>\n",
       "      <td>79.422592</td>\n",
       "      <td>3690.20505</td>\n",
       "      <td>879.55459</td>\n",
       "      <td>136.21903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10738.0</td>\n",
       "      <td>2030.37662</td>\n",
       "      <td>4025.3907</td>\n",
       "      <td>2083.73815</td>\n",
       "      <td>7027.0</td>\n",
       "      <td>9604.89564</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>333.34681</td>\n",
       "      <td>5327.345738</td>\n",
       "      <td>...</td>\n",
       "      <td>2040.30668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262.24513</td>\n",
       "      <td>762.62556</td>\n",
       "      <td>81.838873</td>\n",
       "      <td>3646.41773</td>\n",
       "      <td>873.10075</td>\n",
       "      <td>134.8199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>8790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>AVG</td>\n",
       "      <td>10997.146918</td>\n",
       "      <td>1564.022831</td>\n",
       "      <td>4931.148402</td>\n",
       "      <td>2117.857306</td>\n",
       "      <td>7497.783904</td>\n",
       "      <td>7916.474886</td>\n",
       "      <td>2514.986416</td>\n",
       "      <td>225.077055</td>\n",
       "      <td>5581.348174</td>\n",
       "      <td>...</td>\n",
       "      <td>2085.947489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.678539</td>\n",
       "      <td>558.158676</td>\n",
       "      <td>85.740868</td>\n",
       "      <td>3211.152968</td>\n",
       "      <td>1102.297945</td>\n",
       "      <td>96.02637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>SUM</td>\n",
       "      <td>96335007.0</td>\n",
       "      <td>13700840.00004</td>\n",
       "      <td>43196859.99994</td>\n",
       "      <td>18552429.9994</td>\n",
       "      <td>65680587.0</td>\n",
       "      <td>69348319.99982</td>\n",
       "      <td>22031281.0</td>\n",
       "      <td>1971675.00026</td>\n",
       "      <td>48892609.999998</td>\n",
       "      <td>...</td>\n",
       "      <td>18272900.00016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2861704.00023</td>\n",
       "      <td>4889469.99973</td>\n",
       "      <td>751090.0</td>\n",
       "      <td>28129699.99991</td>\n",
       "      <td>9656130.00026</td>\n",
       "      <td>841190.99979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>MAX</td>\n",
       "      <td>13241.0</td>\n",
       "      <td>2572.98964</td>\n",
       "      <td>10758.28217</td>\n",
       "      <td>4654.11663</td>\n",
       "      <td>12204.0</td>\n",
       "      <td>12216.75958</td>\n",
       "      <td>4301.0</td>\n",
       "      <td>453.05723</td>\n",
       "      <td>10494.917239</td>\n",
       "      <td>...</td>\n",
       "      <td>4325.80471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>672.99677</td>\n",
       "      <td>879.36142</td>\n",
       "      <td>161.223289</td>\n",
       "      <td>4743.21544</td>\n",
       "      <td>1772.54182</td>\n",
       "      <td>175.1632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>MIN</td>\n",
       "      <td>9039.0</td>\n",
       "      <td>914.52522</td>\n",
       "      <td>2949.70715</td>\n",
       "      <td>1364.112</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>5678.58864</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>114.59643</td>\n",
       "      <td>3871.949411</td>\n",
       "      <td>...</td>\n",
       "      <td>1160.56837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.64317</td>\n",
       "      <td>363.0982</td>\n",
       "      <td>59.481023</td>\n",
       "      <td>2400.08571</td>\n",
       "      <td>701.10125</td>\n",
       "      <td>64.09834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8795 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index Load_AESO_2030.dat Load_AVA_2030.dat Load_AZPS_2030.dat  \\\n",
       "0     Year               2030              2030               2030   \n",
       "1        1            10961.0        1855.42866         3499.07666   \n",
       "2        2            10826.0         1920.4559         3790.31341   \n",
       "3        3            10744.0        1977.53983         3921.62148   \n",
       "4        4            10738.0        2030.37662          4025.3907   \n",
       "...    ...                ...               ...                ...   \n",
       "8790  8790                NaN               NaN                NaN   \n",
       "mean   AVG       10997.146918       1564.022831        4931.148402   \n",
       "sum    SUM         96335007.0    13700840.00004     43196859.99994   \n",
       "max    MAX            13241.0        2572.98964        10758.28217   \n",
       "min    MIN             9039.0         914.52522         2949.70715   \n",
       "\n",
       "     Load_BANC_2030.dat Load_BCHA_2030.dat Load_BPAT_2030.dat  \\\n",
       "0                  2030               2030               2030   \n",
       "1            1852.90065             8020.0         8549.39306   \n",
       "2            1978.66392             7440.0          9054.1644   \n",
       "3              2005.747             7173.0         9346.09489   \n",
       "4            2083.73815             7027.0         9604.89564   \n",
       "...                 ...                ...                ...   \n",
       "8790                NaN                NaN                NaN   \n",
       "mean        2117.857306        7497.783904        7916.474886   \n",
       "sum       18552429.9994         65680587.0     69348319.99982   \n",
       "max          4654.11663            12204.0        12216.75958   \n",
       "min            1364.112             3450.0         5678.58864   \n",
       "\n",
       "     Load_CFE_2030.dat Load_CHPD_2030.dat Load_CIPB_2030_CEC.dat  ...  \\\n",
       "0                 2030               2030                   2030  ...   \n",
       "1               1775.0          334.84827            4769.321035  ...   \n",
       "2               1707.0          341.05731            5013.626145  ...   \n",
       "3               1665.0          335.90945            5170.056636  ...   \n",
       "4               1639.0          333.34681            5327.345738  ...   \n",
       "...                ...                ...                    ...  ...   \n",
       "8790               NaN                NaN                    NaN  ...   \n",
       "mean       2514.986416         225.077055            5581.348174  ...   \n",
       "sum         22031281.0      1971675.00026        48892609.999998  ...   \n",
       "max             4301.0          453.05723           10494.917239  ...   \n",
       "min             1383.0          114.59643            3871.949411  ...   \n",
       "\n",
       "     Load_TEPC_2030.dat Load_TH_Malin_2030.dat Load_TH_Mead_2030.dat  \\\n",
       "0                  2030                   2030                  2030   \n",
       "1             2122.3013                    0.0                   0.0   \n",
       "2            2114.66879                    0.0                   0.0   \n",
       "3            2069.61747                    0.0                   0.0   \n",
       "4            2040.30668                    0.0                   0.0   \n",
       "...                 ...                    ...                   ...   \n",
       "8790                NaN                    NaN                   NaN   \n",
       "mean        2085.947489                    0.0                   0.0   \n",
       "sum      18272900.00016                    0.0                   0.0   \n",
       "max          4325.80471                    0.0                   0.0   \n",
       "min          1160.56837                    0.0                   0.0   \n",
       "\n",
       "     Load_TH_PV_2030.dat Load_TIDC_2030.dat Load_TPWR_2030.dat  \\\n",
       "0                   2030               2030               2030   \n",
       "1                    0.0          223.79283          695.48727   \n",
       "2                    0.0          255.11039          732.00902   \n",
       "3                    0.0           257.7363          748.87075   \n",
       "4                    0.0          262.24513          762.62556   \n",
       "...                  ...                ...                ...   \n",
       "8790                 NaN                NaN                NaN   \n",
       "mean                 0.0         326.678539         558.158676   \n",
       "sum                  0.0      2861704.00023      4889469.99973   \n",
       "max                  0.0          672.99677          879.36142   \n",
       "min                  0.0          194.64317           363.0982   \n",
       "\n",
       "     Load_VEA_2030.dat Load_WACM_2030.dat Load_WALC_2030.dat  \\\n",
       "0                 2030               2030               2030   \n",
       "1            73.266478         3608.86928          873.76981   \n",
       "2            77.019502         3649.12892           897.7324   \n",
       "3            79.422592         3690.20505          879.55459   \n",
       "4            81.838873         3646.41773          873.10075   \n",
       "...                ...                ...                ...   \n",
       "8790               NaN                NaN                NaN   \n",
       "mean         85.740868        3211.152968        1102.297945   \n",
       "sum           751090.0     28129699.99991      9656130.00026   \n",
       "max         161.223289         4743.21544         1772.54182   \n",
       "min          59.481023         2400.08571          701.10125   \n",
       "\n",
       "     Load_WAUW_2030.dat  \n",
       "0                  2030  \n",
       "1             136.69212  \n",
       "2             136.43041  \n",
       "3             136.21903  \n",
       "4              134.8199  \n",
       "...                 ...  \n",
       "8790                NaN  \n",
       "mean           96.02637  \n",
       "sum        841190.99979  \n",
       "max            175.1632  \n",
       "min            64.09834  \n",
       "\n",
       "[8795 rows x 44 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = format_scaled_tell_loads(data_dir = data_dir,\n",
    "                                     year_to_process = '2058')\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a2b9d-6f4f-414d-b826-fb88975e819b",
   "metadata": {},
   "source": [
    "## Create a Function to Create Summary Plots of the Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b83b7-b578-406c-bc98-c495ba2e833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_plots(data_dir: str, year_to_process: str, image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Read in the raw data .csv file:\n",
    "    gv_df = pd.read_csv((data_dir + 'wecc_load_2035.csv'))\n",
    "    \n",
    "    # Strip the unecessary bits from the column names:\n",
    "    gv_df.columns = gv_df.columns.str.replace(\"_CEC\", \"\")\n",
    "    gv_df.columns = gv_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "    gv_df.columns = gv_df.columns.str.replace(\"Load_\", \"\")\n",
    "    \n",
    "    # Delete the random column:\n",
    "    del gv_df[\"Unnamed: 38\"]\n",
    "    \n",
    "    # Subset to just the annual total demand by BA:\n",
    "    gv_stats = gv_df[8791:8795]\n",
    "    \n",
    "    # Reshape the dataframe and rename the index column:\n",
    "    gv_stats_df = pd.melt(gv_stats, id_vars='Index', var_name='BA', value_name='GV_Value')\n",
    "    gv_stats_df.rename(columns={'Index': 'Statistic'}, inplace=True)\n",
    "    \n",
    "    # Drop the first row and last 4 rows:\n",
    "    gv_df = gv_df.tail(-1).iloc[:-4, :]\n",
    "    \n",
    "    # Compute the hourly total load across BAs:\n",
    "    gv_df['GV_Total_Load_MWh'] = gv_df.sum(axis=1)\n",
    "    \n",
    "    # Copy the total load to a new dataframe:\n",
    "    gv_load_df = gv_df[['Index', 'GV_Total_Load_MWh']].copy().iloc[0:8760, :]\n",
    "    gv_load_df.rename(columns={'Index': 'Hour'}, inplace=True)\n",
    "    \n",
    "    # Set the output filename:\n",
    "    if year_to_process == '2009':\n",
    "       output_filename = 'TELL_Loads_2035_Based_on_2009_Weather.csv'\n",
    "    if year_to_process == '2015':\n",
    "       output_filename = 'TELL_Loads_2035_Based_on_2015_Weather.csv'\n",
    "    if year_to_process == '2055':\n",
    "       output_filename = 'TELL_Loads_2035_Based_on_2015_Weather_With_Climate_Change.csv'\n",
    "    if year_to_process == '2058':\n",
    "       output_filename = 'TELL_Loads_2035_Based_on_2018_Weather_With_Climate_Change.csv'\n",
    "    \n",
    "    # Read in the raw TELL data .csv file:\n",
    "    tell_df = pd.read_csv((data_dir + output_filename))\n",
    "    \n",
    "    # Strip the unecessary bits from the column names:\n",
    "    tell_df.columns = tell_df.columns.str.replace(\"_CEC\", \"\")\n",
    "    tell_df.columns = tell_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "    tell_df.columns = tell_df.columns.str.replace(\"Load_\", \"\")\n",
    "    \n",
    "    # Subset to just the annual total demand by BA:\n",
    "    tell_stats = tell_df[8791:8795]\n",
    "    \n",
    "    # Reshape the dataframe and rename the index column:\n",
    "    tell_stats_df = pd.melt(tell_stats, id_vars='Index', var_name='BA', value_name='TELL_Value')\n",
    "    tell_stats_df.rename(columns={'Index': 'Statistic'}, inplace=True)\n",
    "    \n",
    "    # Merge the two statistics dataframes together:\n",
    "    stats_df = pd.merge(gv_stats_df, tell_stats_df, on=['Statistic', 'BA'])\n",
    "    \n",
    "    # Drop the first row and last 4 rows:\n",
    "    tell_df = tell_df.tail(-1).iloc[:-4, :]\n",
    "    \n",
    "    # Compute the hourly total load across BAs:\n",
    "    tell_df['TELL_Total_Load_MWh'] = tell_df.sum(axis=1)\n",
    "    \n",
    "    # Copy the total load to a new dataframe:\n",
    "    tell_load_df = tell_df[['Index', 'TELL_Total_Load_MWh']].copy().iloc[0:8760, :]\n",
    "    tell_load_df.rename(columns={'Index': 'Hour'}, inplace=True)\n",
    "    \n",
    "    # Merge the two load dataframes together:\n",
    "    load_df = pd.merge(gv_load_df, tell_load_df, on=['Hour'])\n",
    "    \n",
    "    # Compute the min and max loads:\n",
    "    min_load = load_df[['GV_Total_Load_MWh','TELL_Total_Load_MWh']].min().min()\n",
    "    max_load = load_df[['GV_Total_Load_MWh','TELL_Total_Load_MWh']].max().max()\n",
    "    \n",
    "    # Subset the statistics dataframe:\n",
    "    avg_df = stats_df.loc[stats_df['Statistic'] == 'AVG']; avg_min = 0.95*avg_df[['GV_Value','TELL_Value']].min().min(); avg_max = 1.05*avg_df[['GV_Value','TELL_Value']].max().max()\n",
    "    sum_df = stats_df.loc[stats_df['Statistic'] == 'SUM']; sum_min = 0.95*sum_df[['GV_Value','TELL_Value']].min().min(); sum_max = 1.05*sum_df[['GV_Value','TELL_Value']].max().max()\n",
    "    min_df = stats_df.loc[stats_df['Statistic'] == 'MIN']; min_min = 0.95*min_df[['GV_Value','TELL_Value']].min().min(); min_max = 1.05*min_df[['GV_Value','TELL_Value']].max().max()\n",
    "    max_df = stats_df.loc[stats_df['Statistic'] == 'MAX']; max_min = 0.95*max_df[['GV_Value','TELL_Value']].min().min(); max_max = 1.05*max_df[['GV_Value','TELL_Value']].max().max()\n",
    "    \n",
    "    # Set the output filename:\n",
    "    if year_to_process == '2009':\n",
    "       load_filename = 'Load_Time_Series_2009_Weather.png'\n",
    "       stats_filename = 'Load_Statistics_2009_Weather.png'\n",
    "       plot_title_a = 'TELL Total Loads Based on 2009 Weather'\n",
    "    if year_to_process == '2015':\n",
    "       load_filename = 'Load_Time_Series_2015_Weather.png'\n",
    "       stats_filename = 'Load_Statistics_2015_Weather.png'\n",
    "       plot_title_a = 'TELL Total Loads Based on 2015 Weather'\n",
    "    if year_to_process == '2055':\n",
    "       load_filename = 'Load_Time_Series_2015_Weather_With_Climate_Change.png'\n",
    "       stats_filename = 'Load_Statistics_2015_Weather_With_Climate_Change.png'\n",
    "       plot_title_a = 'TELL Total Loads Based on 2015 Weather With Climate Change'\n",
    "    if year_to_process == '2058':\n",
    "       load_filename = 'Load_Time_Series_2018_Weather_With_Climate_Change.png'\n",
    "       stats_filename = 'Load_Statistics_2018_Weather_With_Climate_Change.png'\n",
    "       plot_title_a = 'TELL Total Loads Based on 2018 Weather With Climate Change'\n",
    "    \n",
    "    # Make the total load time series plots:\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot(load_df['Hour'], load_df['GV_Total_Load_MWh'], color='black', linestyle='-', label='Original GridView Loads', linewidth=0.5)\n",
    "    plt.xlim([0, 8760]); plt.xticks([0, 8760],['0','8760']); plt.xlabel('')\n",
    "    plt.ylim([min_load, max_load]); plt.ylabel('WECC Total Load [MWh]')\n",
    "    plt.legend(loc='upper left', prop={'size': 12})\n",
    "    plt.title('Original Total Loads for 2035')\n",
    "        \n",
    "    plt.subplot(212)\n",
    "    plt.plot(load_df['Hour'], load_df['TELL_Total_Load_MWh'], color='black', linestyle='-', label='TELL Total Loads', linewidth=0.5)\n",
    "    plt.xlim([0, 8760]); plt.xticks([0, 8760],['0','8760']); plt.xlabel('Hour of Year [--->]')\n",
    "    plt.ylim([min_load, max_load]); plt.ylabel('WECC Total Load [MWh]') \n",
    "    plt.legend(loc='upper left', prop={'size': 12})\n",
    "    plt.title(plot_title_a)\n",
    "        \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, load_filename), dpi=image_resolution, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Make the statistics plots:\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.plot([avg_min, avg_max], [avg_min, avg_max], color='k', linestyle='-', linewidth=1)\n",
    "    plt.scatter(avg_df['GV_Value'], avg_df['TELL_Value'], s=50, c='blue')\n",
    "    plt.xlim([avg_min, avg_max]); plt.ylim([avg_min, avg_max]);\n",
    "    plt.xlabel('Original GridView Average Load [MWh]')\n",
    "    plt.ylabel('TELL Average Load [MWh]')\n",
    "    plt.title('Balancing Authority Annual Average Load')\n",
    "        \n",
    "    plt.subplot(222)\n",
    "    plt.plot([sum_min, sum_max], [sum_min, sum_max], color='k', linestyle='-', linewidth=1)\n",
    "    plt.scatter(sum_df['GV_Value'], sum_df['TELL_Value'], s=50, c='blue')\n",
    "    plt.xlim([sum_min, sum_max]); plt.ylim([sum_min, sum_max]);\n",
    "    plt.xlabel('Original GridView Annual Total Load [MWh]')\n",
    "    plt.ylabel('TELL Annual Total Load [MWh]')\n",
    "    plt.title('Balancing Authority Annual Total Load')\n",
    "        \n",
    "    plt.subplot(223)\n",
    "    plt.plot([min_min, min_max], [min_min, min_max], color='k', linestyle='-', linewidth=1)\n",
    "    plt.plot([min_min, min_max], [min_min, 0.9*min_max], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([min_min, min_max], [min_min, 1.1*min_max], color='k', linestyle='--', linewidth=1)\n",
    "    plt.scatter(min_df['GV_Value'], min_df['TELL_Value'], s=50, c='blue')\n",
    "    plt.xlim([min_min, min_max]); plt.ylim([min_min, min_max]);\n",
    "    plt.xlabel('Original GridView Minimum Load [MWh]')\n",
    "    plt.ylabel('TELL Minimum Load [MWh]')\n",
    "    plt.title('Balancing Authority Annual Minimum Load')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot([max_min, max_max], [max_min, max_max], color='k', linestyle='-', linewidth=1)\n",
    "    plt.plot([max_min, max_max], [max_min, 0.9*max_max], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([max_min, max_max], [max_min, 1.1*max_max], color='k', linestyle='--', linewidth=1)\n",
    "    plt.scatter(max_df['GV_Value'], max_df['TELL_Value'], s=50, c='blue')\n",
    "    plt.xlim([max_min, max_max]); plt.ylim([max_min, max_max]);\n",
    "    plt.xlabel('Original GridView Maximum Load [MWh]')\n",
    "    plt.ylabel('TELL Maximum Load [MWh]')\n",
    "    plt.title('Balancing Authority Annual Maximum Load')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.15, hspace=0.4)\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, stats_filename), dpi=image_resolution, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abac0e8-534e-4599-aa2d-7d8e0489eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_summary_plots(data_dir = data_dir,\n",
    "                     year_to_process = '2015',\n",
    "                     image_output_dir = plot_dir, \n",
    "                     image_resolution = 300, \n",
    "                     save_images = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8e933-ff9f-4ea3-b904-fb1d75719146",
   "metadata": {},
   "source": [
    "## Create a Function to Create Plots Quantifying the Climate Change Impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfe36f-4a09-40eb-b7bb-94845448d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climate_change_impact_plots(data_dir: str, year_to_process: str, image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Set the output filename:\n",
    "    if year_to_process == '2015':\n",
    "       base_filename = 'TELL_Loads_2035_Based_on_2015_Weather.csv'\n",
    "       clim_filename = 'TELL_Loads_2035_Based_on_2015_Weather_With_Climate_Change.csv'\n",
    "    if year_to_process == '2018':\n",
    "       base_filename = 'TELL_Loads_2035_Based_on_2018_Weather.csv'\n",
    "       clim_filename = 'TELL_Loads_2035_Based_on_2018_Weather_With_Climate_Change.csv'\n",
    "    \n",
    "    # Read in the raw TELL data .csv file:\n",
    "    base_tell_df = pd.read_csv((data_dir + base_filename))\n",
    "    \n",
    "    # Strip the unecessary bits from the column names:\n",
    "    base_tell_df.columns = base_tell_df.columns.str.replace(\"_CEC\", \"\")\n",
    "    base_tell_df.columns = base_tell_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "    base_tell_df.columns = base_tell_df.columns.str.replace(\"Load_\", \"\")\n",
    "    \n",
    "    # Drop the first row and last 4 rows:\n",
    "    base_tell_df = base_tell_df.tail(-1).iloc[:-4, :]\n",
    "    \n",
    "    # Compute the hourly total load across BAs:\n",
    "    base_tell_df['TELL_Total_Load_MWh'] = base_tell_df.sum(axis=1)\n",
    "    \n",
    "    # Copy the total load to a new dataframe:\n",
    "    tell_base_load_df = base_tell_df[['Index', 'TELL_Total_Load_MWh']].copy().iloc[0:8760, :]\n",
    "    tell_base_load_df.rename(columns={'Index': 'Hour', 'TELL_Total_Load_MWh': 'Base_Load_MWh'}, inplace=True)\n",
    "    \n",
    "      \n",
    "    # Read in the raw TELL data .csv file:\n",
    "    clim_tell_df = pd.read_csv((data_dir + clim_filename))\n",
    "    \n",
    "    # Strip the unecessary bits from the column names:\n",
    "    clim_tell_df.columns = clim_tell_df.columns.str.replace(\"_CEC\", \"\")\n",
    "    clim_tell_df.columns = clim_tell_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "    clim_tell_df.columns = clim_tell_df.columns.str.replace(\"Load_\", \"\")\n",
    "    \n",
    "    # Drop the first row and last 4 rows:\n",
    "    clim_tell_df = clim_tell_df.tail(-1).iloc[:-4, :]\n",
    "    \n",
    "    # Compute the hourly total load across BAs:\n",
    "    clim_tell_df['TELL_Total_Load_MWh'] = clim_tell_df.sum(axis=1)\n",
    "    \n",
    "    # Copy the total load to a new dataframe:\n",
    "    tell_clim_load_df = clim_tell_df[['Index', 'TELL_Total_Load_MWh']].copy().iloc[0:8760, :]\n",
    "    tell_clim_load_df.rename(columns={'Index': 'Hour', 'TELL_Total_Load_MWh': 'Clim_Load_MWh'}, inplace=True)\n",
    "    \n",
    "    # Merge the loads with and without climate change together:\n",
    "    tell_load_df = tell_base_load_df.merge(tell_clim_load_df, on='Hour', how='left')\n",
    "    \n",
    "    # Compute the absolute and relative climate change impact:\n",
    "    tell_load_df['Load_Difference_MWh'] = tell_load_df['Clim_Load_MWh'] - tell_load_df['Base_Load_MWh']\n",
    "    tell_load_df['Load_Difference_%'] = 100*(tell_load_df['Load_Difference_MWh']/tell_load_df['Base_Load_MWh'])\n",
    "    \n",
    "    # Compute the min and max loads:\n",
    "    min_load = 0.98*tell_load_df[['Clim_Load_MWh','Base_Load_MWh']].min().min()\n",
    "    max_load = 1.02*tell_load_df[['Clim_Load_MWh','Base_Load_MWh']].max().max()\n",
    "    \n",
    "    # Make the total load time series plots:\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.plot(tell_load_df['Hour'], tell_load_df['Base_Load_MWh'], color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.xlim([0, 8760]);\n",
    "    plt.xticks([0, 8760],['0','8760']);\n",
    "    plt.xlabel('')\n",
    "    #if year_to_process == '2015':\n",
    "       #plt.xlim([4224, 4392]);\n",
    "       #plt.xticks([4224, 4392],['25-Jun','2-Jul']);\n",
    "    #if year_to_process == '2018':\n",
    "       #plt.xlim([4872, 5016]);\n",
    "       #plt.xticks([4872, 5016],['22-Jul','28-Jul']);\n",
    "    plt.xlabel('')\n",
    "    plt.ylim([min_load, max_load]); plt.ylabel('Total Load [MWh]')\n",
    "    plt.title((year_to_process + ' Weather Year Loads in 2035'))\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.plot(tell_load_df['Hour'], tell_load_df['Clim_Load_MWh'], color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.xlim([0, 8760]);\n",
    "    plt.xticks([0, 8760],['0','8760']);\n",
    "    plt.xlabel('')\n",
    "    #if year_to_process == '2015':\n",
    "       #plt.xlim([4224, 4392]);\n",
    "       #plt.xticks([4224, 4392],['25-Jun','2-Jul']);\n",
    "    #if year_to_process == '2018':\n",
    "       #plt.xlim([4872, 5016]);\n",
    "       #plt.xticks([4872, 5016],['22-Jul','28-Jul']);\n",
    "    plt.xlabel('')\n",
    "    plt.ylim([min_load, max_load]); plt.ylabel('Total Load [MWh]')\n",
    "    plt.title((year_to_process + ' Weather Year Loads with Climate Change in 2035'))\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(tell_load_df['Hour'], tell_load_df['Load_Difference_MWh'], color='red', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, 8760], [0, 0], color='gray', linestyle='-', linewidth=1)\n",
    "    plt.xlim([0, 8760]);\n",
    "    plt.xticks([0, 8760],['0','8760']);\n",
    "    plt.xlabel('')\n",
    "    #if year_to_process == '2015':\n",
    "       #plt.xlim([4224, 4392]);\n",
    "       #plt.xticks([4224, 4392],['25-Jun','2-Jul']);\n",
    "    #if year_to_process == '2018':\n",
    "       #plt.xlim([4872, 5016]);\n",
    "       #plt.xticks([4872, 5016],['22-Jul','28-Jul']);\n",
    "    plt.xlabel('Time [Hours]')\n",
    "    plt.ylim([-30000, 30000]); \n",
    "    plt.ylabel('Absolute Load Difference [MWh]')\n",
    "    plt.title('Absolute Load Difference Due to Climate Change')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot(tell_load_df['Hour'], tell_load_df['Load_Difference_%'], color='blue', linestyle='-', linewidth=0.5)\n",
    "    plt.plot([0, 8760], [0, 0], color='gray', linestyle='-', linewidth=1)\n",
    "    plt.xlim([0, 8760]);\n",
    "    plt.xticks([0, 8760],['0','8760']);\n",
    "    plt.xlabel('')\n",
    "    #if year_to_process == '2015':\n",
    "       #plt.xlim([4224, 4392]);\n",
    "       #plt.xticks([4224, 4392],['25-Jun','2-Jul']);\n",
    "    #if year_to_process == '2018':\n",
    "       #plt.xlim([4872, 5016]);\n",
    "       #plt.xticks([4872, 5016],['22-Jul','28-Jul']);\n",
    "    plt.xlabel('Time [Hours]')\n",
    "    plt.ylim([-15, 15]); \n",
    "    plt.ylabel('Relative Load Difference [%]')\n",
    "    plt.title('Relative Load Difference Due to Climate Change')\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join((image_output_dir + 'Climate_Change_Impact_' + year_to_process + '_Weather_Year.png')), dpi=image_resolution, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23034725-c709-4152-b0ab-27fc6e5cff61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "climate_change_impact_plots(data_dir = data_dir,\n",
    "                            year_to_process = '2018',\n",
    "                            image_output_dir = plot_dir, \n",
    "                            image_resolution = 300, \n",
    "                            save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b274c5-0507-4f13-a2eb-6881c2b2a29d",
   "metadata": {},
   "source": [
    "## Create a Function to Plot the Basic 8760 Time Series for a Given GridView Input File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51938817-417c-4338-a6fe-151f084cbc5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_time_series_plots(data_dir: str, year_to_process: str, image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Set the output filename:\n",
    "    if year_to_process == '2035':\n",
    "       input_filename = 'wecc_load_2035.csv'\n",
    "       plot_title = '2035 Base Total Load'\n",
    "       line_color = 'black' \n",
    "    if year_to_process == '2015':\n",
    "       input_filename = 'TELL_Loads_2035_Based_on_2015_Weather_With_Climate_Change.csv'\n",
    "       plot_title = '2035 Total Load Based on 2015 Weather With Climate Change'\n",
    "       line_color = 'blue' \n",
    "    if year_to_process == '2018':\n",
    "       input_filename = 'TELL_Loads_2035_Based_on_2018_Weather_With_Climate_Change.csv'\n",
    "       plot_title = '2035 Total Load Based on 2015 Weather With Climate Change'\n",
    "       line_color = 'red'  \n",
    "    \n",
    "    # Read in the raw TELL data .csv file:\n",
    "    tell_df = pd.read_csv((data_dir + input_filename))\n",
    "    \n",
    "    # Strip the unecessary bits from the column names:\n",
    "    tell_df.columns = tell_df.columns.str.replace(\"_CEC\", \"\")\n",
    "    tell_df.columns = tell_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "    tell_df.columns = tell_df.columns.str.replace(\"Load_\", \"\")\n",
    "    \n",
    "    # Subset to just the annual total demand by BA:\n",
    "    tell_stats = tell_df[8791:8795]\n",
    "    \n",
    "    # Reshape the dataframe and rename the index column:\n",
    "    tell_stats_df = pd.melt(tell_stats, id_vars='Index', var_name='BA', value_name='TELL_Value')\n",
    "    tell_stats_df.rename(columns={'Index': 'Statistic'}, inplace=True)\n",
    "    \n",
    "    # Drop the first row and last 4 rows:\n",
    "    tell_df = tell_df.tail(-1).iloc[:-4, :]\n",
    "    \n",
    "    # Compute the hourly total load across BAs:\n",
    "    tell_df['TELL_Total_Load_MWh'] = tell_df.sum(axis=1)\n",
    "    \n",
    "    # Copy the total load to a new dataframe:\n",
    "    tell_load_df = tell_df[['Index', 'TELL_Total_Load_MWh']].copy().iloc[0:8760, :]\n",
    "    tell_load_df.rename(columns={'Index': 'Hour'}, inplace=True)\n",
    "    \n",
    "    print(tell_load_df['TELL_Total_Load_MWh'].max())\n",
    "    \n",
    "    # Make the total load time series plots:\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    if year_to_process == '2015':\n",
    "       plt.fill_between([4200, 4200, 4392, 4392], [80000, 220000, 220000, 80000], color='blue', alpha=0.15)\n",
    "    if year_to_process == '2018':\n",
    "       plt.fill_between([4848, 4848, 5016, 5016], [80000, 220000, 220000, 80000], color='red', alpha=0.15)\n",
    "    plt.plot(tell_load_df['Hour'], tell_load_df['TELL_Total_Load_MWh'], color=line_color, linestyle='-', linewidth=0.75)\n",
    "    plt.xlim([0, 8760]); \n",
    "    plt.xticks([0, 744, 1416, 2160, 2880, 3624, 4344, 5088, 5832, 6552, 7296, 8016, 8760],['1-Jan', '1-Feb', '1-Mar', '1-Apr', '1-May', '1-Jun', '1-Jul', '1-Aug', '1-Sep', '1-Oct', '1-Nov', '1-Dec', '1-Jan']); \n",
    "    plt.xlabel('')\n",
    "    plt.ylim([80000, 220000]); \n",
    "    plt.ylabel('WECC Total Load [MWh]')\n",
    "    plt.title(plot_title)\n",
    "        \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, 'WECC_Loads_' + year_to_process + '.png'), dpi=image_resolution, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1e248-616f-4cbc-9345-fd8622a1ce5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_time_series_plots(data_dir = data_dir,\n",
    "                         year_to_process = '2035',\n",
    "                         image_output_dir = plot_dir, \n",
    "                         image_resolution = 300, \n",
    "                         save_images = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f89a62-2169-49c8-a2a5-effcfaf1e2bb",
   "metadata": {},
   "source": [
    "## Create a Function to Calculate Changes in Minimum and Maximum Loads by BA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e915ac3-733b-4080-bf31-8410942042f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_delta_plots(data_dir: str, image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \n",
    "    # Loop over the years\n",
    "    for year in [2015, 2018, 2035]:\n",
    "        \n",
    "        # Set the output filename:\n",
    "        if str(year) == '2035':\n",
    "           input_filename = 'wecc_load_2035.csv'\n",
    "        if str(year) == '2015':\n",
    "           input_filename = 'TELL_Loads_2035_Based_on_2015_Weather_With_Climate_Change.csv'\n",
    "        if str(year) == '2018':\n",
    "           input_filename = 'TELL_Loads_2035_Based_on_2018_Weather_With_Climate_Change.csv' \n",
    "    \n",
    "        # Read in the raw TELL data .csv file:\n",
    "        tell_df = pd.read_csv((data_dir + input_filename))\n",
    "    \n",
    "        # Strip the unecessary bits from the column names:\n",
    "        tell_df.columns = tell_df.columns.str.replace(\"_CEC\", \"\")\n",
    "        tell_df.columns = tell_df.columns.str.replace(\"_2030.dat\", \"\")\n",
    "        tell_df.columns = tell_df.columns.str.replace(\"Load_\", \"\")\n",
    "    \n",
    "        # Subset to just the annual max demand by BA:\n",
    "        max_df = pd.DataFrame(tell_df.filter(items=[8793], axis=0).drop('Index', axis=1).squeeze()).reset_index()\n",
    "        max_df.rename(columns={'index': 'BA'}, inplace=True)\n",
    "        if year == 2015:\n",
    "           max_df.rename(columns={max_df.columns[1]: 'Max_Load_2015'}, inplace=True)\n",
    "        if year == 2018:\n",
    "           max_df.rename(columns={max_df.columns[1]: 'Max_Load_2018'}, inplace=True)\n",
    "        if year == 2035:\n",
    "           max_df.rename(columns={max_df.columns[1]: 'Max_Load_2035'}, inplace=True)\n",
    "    \n",
    "        # Subset to just the annual min demand by BA:\n",
    "        min_df = pd.DataFrame(tell_df.filter(items=[8794], axis=0).drop('Index', axis=1).squeeze()).reset_index()\n",
    "        min_df.rename(columns={'index': 'BA'}, inplace=True)\n",
    "        if year == 2015:\n",
    "           min_df.rename(columns={min_df.columns[1]: 'Min_Load_2015'}, inplace=True)\n",
    "        if year == 2018:\n",
    "           min_df.rename(columns={min_df.columns[1]: 'Min_Load_2018'}, inplace=True)\n",
    "        if year == 2035:\n",
    "           min_df.rename(columns={min_df.columns[1]: 'Min_Load_2035'}, inplace=True)\n",
    "    \n",
    "        if year == 2015:\n",
    "           # Assign the output_df as the temp_df:  \n",
    "           output_df = max_df.merge(min_df, on=['BA'])\n",
    "        else:\n",
    "           # Merge the output_df and temp_df dataframes based on common BA names:\n",
    "           output_df = output_df.merge(max_df, on=['BA'])\n",
    "           output_df = output_df.merge(min_df, on=['BA'])\n",
    "        \n",
    "        # Clean up and move to the next year:\n",
    "        del tell_df, max_df, min_df, input_filename\n",
    "    \n",
    "    # Compute the min and max loads:\n",
    "    max_min_load = 1.05*output_df[['Min_Load_2015', 'Min_Load_2018', 'Min_Load_2035']].max().max().max()\n",
    "    min_max_load = 0.95*output_df[['Max_Load_2015', 'Max_Load_2018', 'Max_Load_2035']].min().min().min()\n",
    "    max_max_load = 1.05*output_df[['Max_Load_2015', 'Max_Load_2018', 'Max_Load_2035']].max().max().max()\n",
    "    \n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.rcParams['font.size'] = 15\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    plt.plot([0, max_min_load], [0, max_min_load], color='k', linestyle='-', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 0.8*max_min_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 0.9*max_min_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 1.1*max_min_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 1.2*max_min_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.scatter(output_df['Min_Load_2035'], output_df['Min_Load_2015'], s=50, c='blue')\n",
    "    plt.xlim([0, max_min_load]); plt.ylim([0, max_min_load]);\n",
    "    plt.xlabel('NTP Base Year Min Load [MWh]')\n",
    "    plt.ylabel('2015 Weather Year Min Load [MWh]')\n",
    "    plt.title('BA Annual Minimum Load: 2015 Comparison')\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.plot([0, max_min_load], [0, max_min_load], color='k', linestyle='-', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 0.8*max_min_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 0.9*max_min_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 1.1*max_min_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([0, max_min_load], [0, 1.2*max_min_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.scatter(output_df['Min_Load_2035'], output_df['Min_Load_2018'], s=50, c='red')\n",
    "    plt.xlim([0, max_min_load]); plt.ylim([0, max_min_load]);\n",
    "    plt.xlabel('NTP Base Year Min Load [MWh]')\n",
    "    plt.ylabel('2018 Weather Year Min Load [MWh]')\n",
    "    plt.title('BA Annual Minimum Load: 2018 Comparison')\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, max_max_load], color='k', linestyle='-', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 0.8*max_max_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 0.9*max_max_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 1.1*max_max_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 1.2*max_max_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.scatter(output_df['Max_Load_2035'], output_df['Max_Load_2015'], s=50, c='blue')\n",
    "    plt.xlim([min_max_load, max_max_load]); plt.ylim([min_max_load, max_max_load]);\n",
    "    plt.xlabel('NTP Base Year Max Load [MWh]')\n",
    "    plt.ylabel('2015 Weather Year Max Load [MWh]')\n",
    "    plt.title('BA Annual Maximum Load: 2015 Comparison')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, max_max_load], color='k', linestyle='-', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 0.8*max_max_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 0.9*max_max_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 1.1*max_max_load], color='k', linestyle='--', linewidth=1)\n",
    "    plt.plot([min_max_load, max_max_load], [min_max_load, 1.2*max_max_load], color='k', linestyle=':', linewidth=1)\n",
    "    plt.scatter(output_df['Max_Load_2035'], output_df['Max_Load_2018'], s=50, c='red')\n",
    "    plt.xlim([min_max_load, max_max_load]); plt.ylim([min_max_load, max_max_load]);\n",
    "    plt.xlabel('NTP Base Year Max Load [MWh]')\n",
    "    plt.ylabel('2018 Weather Year Max Load [MWh]')\n",
    "    plt.title('BA Annual Maximum Load: 2018 Comparison')\n",
    "    \n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       plt.savefig(os.path.join(image_output_dir, 'Delta_Plots.png'), dpi=image_resolution, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "    return output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b675362-3488-4f98-99e4-e20a2166799c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = create_delta_plots(data_dir = data_dir,\n",
    "                       image_output_dir = plot_dir, \n",
    "                       image_resolution = 300, \n",
    "                       save_images = True)\n",
    "\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2b892-4efd-476d-8b36-db9cca72505d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
